# Rapport sur l'Analyse des Donn√©es GPS et Climatiques

## Introduction
Ce projet porte sur l'analyse des donn√©es GPS, climatiques et d'activit√©s auto-d√©clar√©es recueillies sur une semaine. Les objectifs incluent la segmentation, la visualisation, le nettoyage et l'analyse des trajectoires, ainsi que l'√©valuation des activit√©s par rapport aux donn√©es collect√©es.

### Donn√©es Utilis√©es
- **Donn√©es GPS** : Coordonn√©es spatiales collect√©es √† haute fr√©quence.
- **Donn√©es Climatiques** : Param√®tres √† √©chantillonnage par minute (PM2.5, PM10, NO2, temp√©rature, humidit√©).
- **Donn√©es d'Activit√©s** : Changements contextuels enregistr√©s manuellement.

## M√©thodologie

### Question 1 : Chargement des Donn√©es
#### Approche
1. **Lecture des fichiers CSV** :
   - Donn√©es GPS, climatiques et d'activit√©s charg√©es via la librairie pandas.
   - Normalisation des horodatages pour assurer la coh√©rence temporelle.
2. **Validation des donn√©es** :
   - V√©rification de la compl√©tude des colonnes essentielles (timestamps, latitude, longitude, etc.).
   - Conversion des formats irr√©guliers en un format standard uniforme.

#### R√©sultats
- **GPS** :
  - 81 308 points collect√©s sur 7 jours.
  - Donn√©es pr√™tes pour une segmentation temporelle.
- **Climat** :
  - Donn√©es √©tendues √† 8 jours en raison de l'√©chantillonnage √† haute fr√©quence.
- **Activit√©s** :
  - Alignement temporel avec les donn√©es GPS, pr√©parant les activit√©s √† des analyses crois√©es.

### Question 2 : Segmentation des Donn√©es par Jour
#### Approche
1. **Filtrage Temporel** :
   - Application d'un filtre bas√© sur les dates uniques extraites des timestamps.
2. **Segmentation** :
   - D√©coupage des donn√©es en blocs journaliers.
3. **Validation** :
   - Comptage des jours uniques dans chaque fichier pour assurer l'int√©grit√© des segments.

#### R√©sultats
- **GPS** :
  - 7 jours uniques confirm√©s (√©chantillons : 2019-10-21 √† 2019-10-28, excluant le 2019-10-27).
- **Climat** :
  - 8 jours, refl√©tant un √©chantillonnage plus complet.
- **Activit√©s** :
  - 7 jours align√©s avec les segments GPS.

### Question 3 : Transformation en Types Spatiaux et Visualisation
#### Approche
1. **Conversion en Types Spatiaux** :
   - Utilisation de **GeoPandas** pour convertir les donn√©es GPS en types g√©ographiques (Points).
   - Cr√©ation de trajectoires spatiotemporelles √† l'aide de **MovingPandas**.
2. **Visualisation des Trajectoires** :
   - Repr√©sentation des trajectoires journali√®res.
   - Cartographie des trajets combin√©s pour analyser les zones fr√©quent√©es.
3. **Exportation** :
   - G√©n√©ration de fichiers GeoJSON pour une analyse future.

### Question 4 : Nettoyage des Trajectoires et Validation Visuelle
#### Approche
1. **Calcul de la Vitesse** :
   - La vitesse entre chaque point GPS est calcul√©e en utilisant la distance de Haversine et les diff√©rences temporelles.
   - Les vitesses excessives (>150 km/h) sont filtr√©es.
2. **Lissage des Trajectoires** :
   - Application d'une moyenne mobile sur les coordonn√©es GPS pour r√©duire les fluctuations dues au bruit.
3. **Filtrage des Donn√©es avec DBSCAN** :
   - DBSCAN est utilis√© pour identifier et supprimer les points aberrants dans les donn√©es GPS.
   - Chaque jour est trait√© s√©par√©ment, avec conversion des coordonn√©es g√©ographiques en m√®tres pour une meilleure pr√©cision.

### Question 5 : D√©tection des Arr√™ts et D√©placements
#### Approche
1. **D√©finition des Param√®tres** :
   - Distance seuil pour identifier un arr√™t : 5 m√®tres.
   - Dur√©e seuil pour confirmer un arr√™t : 30 secondes.
2. **Calcul des Arr√™ts et D√©placements** :
   - Identification des arr√™ts en fonction des seuils de distance et de dur√©e.
   - Assignation d'un identifiant unique √† chaque segment (arr√™t ou d√©placement).

### Question 6 : Segmentation Bas√©e sur les Arr√™ts et D√©placements
#### Approche
1. **Cr√©ation des Segments** :
   - Chaque arr√™t et d√©placement est associ√© √† un identifiant de segment unique.
   - D√©termination des temps de d√©but et de fin pour chaque segment.
2. **Propagation aux Donn√©es Climatiques et d'Activit√©s** :
   - Utilisation de la fonction `merge_asof` pour associer chaque segment aux donn√©es climatiques et d'activit√©s correspondantes.
   - Ajustement des tol√©rances temporelles pour maximiser les correspondances.

### Question 7 : Validation des Arr√™ts D√©tect√©s par Rapport aux Activit√©s Auto-Report√©es
#### Approche
1. **Fusion des Donn√©es D√©tect√©es et D√©clar√©es** :
   - Comparaison des arr√™ts d√©tect√©s avec les arr√™ts auto-report√©s en utilisant un appariement temporel pr√©cis.
   - Utilisation de `merge_asof` avec une tol√©rance de 2 minutes pour lier les √©v√©nements GPS aux d√©clarations manuelles.
2. **Optimisation des Seuils de D√©tection** :
   - Ajustement des seuils de distance et de dur√©e d'arr√™t en testant diff√©rentes configurations.
   - S√©lection des param√®tres optimaux en maximisant le taux d'accord entre les arr√™ts d√©tect√©s et d√©clar√©s.
3. **Analyse des Discordances (Mismatches)** :
   - Identification des √©carts entre les arr√™ts auto-report√©s et les arr√™ts d√©tect√©s automatiquement.
   - V√©rification des erreurs potentielles de d√©tection √† l'aide de visualisations des d√©saccords.
4. **Calcul du Taux d‚ÄôAccord** :
   - Cr√©ation d‚Äôune colonne binaire `agreement` indiquant si un arr√™t d√©tect√© correspond √† un arr√™t auto-report√©.
   - Calcul du pourcentage de correspondance entre les deux sources.

### R√©sultats Globaux
- **Taux d'Accord Global** : 69.09 % des arr√™ts d√©tect√©s co√Øncident avec les arr√™ts auto-report√©s.
- **Erreurs de D√©tection** :
  - Nombre total de mismatches : 17.
  - Des erreurs surviennent principalement lorsque les arr√™ts auto-report√©s sont de tr√®s courte dur√©e ou mal align√©s temporellement avec les donn√©es GPS.
- **Optimisation des Param√®tres** :
  - Seuil optimal trouv√© : arr√™t d√©tect√© si la distance < **5 m√®tres** et la dur√©e > **5 secondes**.



# üìÇ Analyse des Trajectoires et Arr√™ts
# MobilityDB Analysis - Trajectories and Stops


## üîç Bilan des Questions 9 √† 14

### **üëâ Question 9  Create & Populate Tables**
### ‚úÖ Create the `trajectories` Table
```sql
CREATE TABLE trajectories (
    id SERIAL PRIMARY KEY,
    traj_id TEXT,
    geometry GEOMETRY(LineString, 4326),
    start_time TIMESTAMP,
    end_time TIMESTAMP,
    is_stop BOOLEAN
);
```

### ‚úÖ Create the `json_import` Table
```sql
CREATE TABLE json_import (
    id SERIAL PRIMARY KEY,
    data JSONB
);
```

### ‚úÖ Load the MF-JSON Data into `json_import`
```sql
INSERT INTO json_import (data)
SELECT jsonb_array_elements(pg_read_file('/tmp/trajectories_mf.json')::jsonb);
```

### ‚úÖ Insert Data into `trajectories` Table
```sql
INSERT INTO trajectories (traj_id, geometry, start_time, end_time, is_stop)
SELECT
    data->>'id' AS traj_id,
    ST_GeomFromGeoJSON(
        jsonb_build_object(
            'type', 'LineString',
            'coordinates', data->'geometry'->'coordinates'
        )::TEXT
    ) AS geometry,
    (data->'properties'->>'start_time')::TIMESTAMP AS start_time,
    (data->'properties'->>'end_time')::TIMESTAMP AS end_time,
    (data->'properties'->>'is_stop')::BOOLEAN AS is_stop
FROM json_import;
```
---
### **üëâ Question 10: Calcul des Centroides et des Distances des Segments d'Arr√™t**
#### üåü Objectif :
D√©terminer la localisation centrale de chaque arr√™t, sa dur√©e et l'incertitude de sa position via la distance maximale par rapport √† son enveloppe convexe.

#### üìù Requ√™te SQL :
```sql
SELECT
    id AS stop_id,
    ST_Centroid(geometry) AS centroid,
    start_time,
    end_time,
    end_time - start_time AS duration,
    ST_MaxDistance(geometry, ST_Envelope(geometry)) AS max_bbox_distance
FROM trajectories
WHERE is_stop = TRUE;
```
#### üìä Analyse des R√©sultats :
- Chaque **stop_id** repr√©sente un segment d'arr√™t identifi√©.
- **ST_Centroid(geometry)** permet d'obtenir un point central approximatif de l'arr√™t.
- **ST_MaxDistance()** donne la distance maximale entre le centroid et l'enveloppe convexe, indiquant le niveau d'incertitude de la position de l'arr√™t.
- Exemples :
  - `stop_id = 1` a dur√© **5min 56s** avec une incertitude de **5.67e-6 degr√©s**.
  - `stop_id = 23` a dur√© **6h11min**, possiblement une r√©sidence.

---
### **üëâ Question 11: Identification des Arr√™ts R√©currents**
#### üåü Objectif :
Associer les arr√™ts proches et dont les bo√Ætes englobantes s'intersectent sous une m√™me **stop_id**.

#### üìù Requ√™te SQL :
```sql
WITH stop_clusters AS (
    SELECT
        t1.id AS stop1_id,
        t2.id AS stop2_id,
        ST_Distance(ST_Centroid(t1.geometry), ST_Centroid(t2.geometry)) AS centroid_distance,
        ST_Intersects(ST_Envelope(t1.geometry), ST_Envelope(t2.geometry)) AS bbox_intersection
    FROM trajectories t1
    JOIN trajectories t2 ON t1.id < t2.id
    WHERE t1.is_stop = TRUE AND t2.is_stop = TRUE
)
UPDATE trajectories
SET stop_id = stop1_id
FROM stop_clusters
WHERE trajectories.id = stop_clusters.stop2_id
AND centroid_distance < 50 -- Seulement si les stops sont √† moins de 50m
AND bbox_intersection = TRUE;
```
#### üìä Analyse des R√©sultats :
- **201 arr√™ts ont √©t√© regroup√©s** sous des identifiants communs.
- Exemples :
  - `stop_id = 1` (45 visites)
  - `stop_id = 178` (36 visites)

---
### **üëâ Question 12: Classement des Arr√™ts par Fr√©quence et Dur√©e**
#### üåü Objectif :
Identifier les arr√™ts les plus visit√©s et les plus longs.

#### üìù Requ√™tes SQL :
**Classement par Fr√©quence :**
```sql
SELECT stop_id, COUNT(*) AS visit_count
FROM trajectories
WHERE is_stop = TRUE
GROUP BY stop_id
ORDER BY visit_count DESC;
```
**Classement par Dur√©e Totale :**
```sql
SELECT stop_id, SUM(end_time - start_time) AS total_duration
FROM trajectories
WHERE is_stop = TRUE
GROUP BY stop_id
ORDER BY total_duration DESC;
```
#### üìä Analyse :
- **Stop_id 1** est le plus visit√© (**45 visites**).
- **Stop_id 269** a la plus longue dur√©e cumul√©e (**12h13min**).

**Attribution des labels "Home" et "Work" :**
```sql
UPDATE trajectories
SET stop_label = 'Home'
WHERE stop_id = (SELECT stop_id FROM trajectories WHERE is_stop = TRUE GROUP BY stop_id ORDER BY COUNT(*) DESC LIMIT 1);

UPDATE trajectories
SET stop_label = 'Work'
WHERE stop_id = (SELECT stop_id FROM trajectories WHERE is_stop = TRUE GROUP BY stop_id ORDER BY COUNT(*) DESC OFFSET 1 LIMIT 1);
```

---
### **üëâ Question 13: Classement des Trajectoires Mobiles par Distance et Dur√©e**
#### üåü Objectif :
Trouver les trajets les plus longs en distance et en temps.

#### üìù Requ√™tes SQL :
**Distance Totale :**
```sql
SELECT id, SUM(ST_Length(geometry::geography)) AS total_distance
FROM trajectories
WHERE is_stop = FALSE
GROUP BY id
ORDER BY total_distance DESC;
```
**Dur√©e Totale :**
```sql
SELECT id, SUM(end_time - start_time) AS total_duration
FROM trajectories
WHERE is_stop = FALSE
GROUP BY id
ORDER BY total_duration DESC;
```
#### üìä Analyse :
- Le trajet `id = 409` est le plus long (**57.2 km**, **9h52min**).
- Le trajet `id = 314` est le 2·µó ∞ plus long (**15.4 km**, **3h03min**).

---
### **üëâ Question 14: Identification des Trajectoires R√©p√©t√©es**
#### üåü Objectif :
Trouver des trajectoires similaires selon diff√©rents crit√®res.

#### üìù Requ√™tes SQL :
**Distances Similaires :**
```sql
SELECT t1.id, t2.id,
       ABS(ST_Length(t1.geometry::geography) - ST_Length(t2.geometry::geography)) AS distance_diff
FROM trajectories t1
JOIN trajectories t2 ON t1.id < t2.id
WHERE t1.is_stop = FALSE AND t2.is_stop = FALSE
ORDER BY distance_diff
LIMIT 10;
```
**Points de D√©part et d'Arriv√©e Similaires :**
```sql
SELECT t1.id AS traj1, t2.id AS traj2
FROM trajectories t1
JOIN trajectories t2
ON t1.id < t2.id
WHERE t1.is_stop = FALSE AND t2.is_stop = FALSE
AND ST_DWithin(ST_StartPoint(t1.geometry)::geography, ST_StartPoint(t2.geometry)::geography, 100)
AND ST_DWithin(ST_EndPoint(t1.geometry)::geography, ST_EndPoint(t2.geometry)::geography, 100)
ORDER BY traj1, traj2;
```
**Distance de Hausdorff :**
```sql
SELECT t1.id AS traj1, t2.id AS traj2,
       ST_HausdorffDistance(t1.geometry, t2.geometry) AS shape_distance
FROM trajectories t1
JOIN trajectories t2 ON t1.id < t2.id
WHERE t1.is_stop = FALSE AND t2.is_stop = FALSE
ORDER BY shape_distance
LIMIT 10;
```
#### üìä Analyse :
- Plusieurs trajets **exactement identiques** ont √©t√© d√©tect√©s (**Hausdorff Distance = 0**).

---
# MobilityDB Analysis: Air Quality Score (AQS) and Temporal Comparisons

## **9Ô∏è‚É£ Create & Populate Tables**

### **1Ô∏è‚É£ Create the `trajectories` Table**
```sql
CREATE TABLE trajectories (
    id SERIAL PRIMARY KEY,
    traj_id TEXT,
    geometry GEOMETRY(LineString, 4326),
    start_time TIMESTAMP,
    end_time TIMESTAMP,
    is_stop BOOLEAN
);
```

### **2Ô∏è‚É£ Create the `json_import` Table**
```sql
CREATE TABLE json_import (
    id SERIAL PRIMARY KEY,
    data JSONB
);
```

### **3Ô∏è‚É£ Load the MF-JSON Data into `json_import`**
```sql
INSERT INTO json_import (data)
SELECT jsonb_array_elements(pg_read_file('/tmp/trajectories_mf.json')::jsonb);
```

### **4Ô∏è‚É£ Insert Data into `trajectories` Table**
```sql
INSERT INTO trajectories (traj_id, geometry, start_time, end_time, is_stop)
SELECT
    data->>'id' AS traj_id,
    ST_GeomFromGeoJSON(
        jsonb_build_object(
            'type', 'LineString',
            'coordinates', data->'geometry'->'coordinates'
        )::TEXT
    ) AS geometry,
    (data->'properties'->>'start_time')::TIMESTAMP AS start_time,
    (data->'properties'->>'end_time')::TIMESTAMP AS end_time,
    (data->'properties'->>'is_stop')::BOOLEAN AS is_stop
FROM json_import;
```

---

## **15Ô∏è‚É£ Compute Air Quality Score (AQS)**
### **Normalize PM2.5, PM10, and NO2 and compute AQS**
```sql
WITH normalized AS (
    SELECT *,
        (PM2_5 - MIN(PM2_5) OVER()) / NULLIF(MAX(PM2_5) OVER() - MIN(PM2_5) OVER(), 0) AS norm_PM2_5,
        (PM10 - MIN(PM10) OVER()) / NULLIF(MAX(PM10) OVER() - MIN(PM10) OVER(), 0) AS norm_PM10,
        (NO2 - MIN(NO2) OVER()) / NULLIF(MAX(NO2) OVER() - MIN(NO2) OVER(), 0) AS norm_NO2
    FROM trajectories
)
SELECT id, start_time, end_time,
       (norm_PM2_5 + norm_PM10 + norm_NO2) / 3 AS AQS
FROM normalized;
```

---

## **16Ô∏è‚É£ Rank Days by Ascending Cumulated AQS**
### **Aggregate AQS per day and rank in ascending order**
```sql
WITH daily_aqs AS (
    SELECT
        DATE(start_time) AS day,
        SUM((PM2_5 - MIN(PM2_5) OVER()) / NULLIF(MAX(PM2_5) OVER() - MIN(PM2_5) OVER(), 0) +
            (PM10 - MIN(PM10) OVER()) / NULLIF(MAX(PM10) OVER() - MIN(PM10) OVER(), 0) +
            (NO2 - MIN(NO2) OVER()) / NULLIF(MAX(NO2) OVER() - MIN(NO2) OVER(), 0)) / 3 AS total_AQS
    FROM trajectories
    GROUP BY day
)
SELECT day, total_AQS
FROM daily_aqs
ORDER BY total_AQS ASC;
```

---

## **17Ô∏è‚É£ Compare AQS Between Day/Night & Stops/Moves**
### **Compute AQS separately for day, night, stops, and moves**
```sql
WITH aqs_by_period AS (
    SELECT
        CASE
            WHEN EXTRACT(HOUR FROM start_time) BETWEEN 6 AND 18 THEN 'Day'
            ELSE 'Night'
        END AS time_period,
        is_stop,
        AVG((PM2_5 - MIN(PM2_5) OVER()) / NULLIF(MAX(PM2_5) OVER() - MIN(PM2_5) OVER(), 0) +
            (PM10 - MIN(PM10) OVER()) / NULLIF(MAX(PM10) OVER() - MIN(PM10) OVER(), 0) +
            (NO2 - MIN(NO2) OVER()) / NULLIF(MAX(NO2) OVER() - MIN(NO2) OVER(), 0)) / 3 AS avg_AQS,
        MIN((PM2_5 - MIN(PM2_5) OVER()) / NULLIF(MAX(PM2_5) OVER() - MIN(PM2_5) OVER(), 0) +
            (PM10 - MIN(PM10) OVER()) / NULLIF(MAX(PM10) OVER() - MIN(PM10) OVER(), 0) +
            (NO2 - MIN(NO2) OVER()) / NULLIF(MAX(NO2) OVER() - MIN(NO2) OVER(), 0)) / 3 AS min_AQS,
        MAX((PM2_5 - MIN(PM2_5) OVER()) / NULLIF(MAX(PM2_5) OVER() - MIN(PM2_5) OVER(), 0) +
            (PM10 - MIN(PM10) OVER()) / NULLIF(MAX(PM10) OVER() - MIN(PM10) OVER(), 0) +
            (NO2 - MIN(NO2) OVER()) / NULLIF(MAX(NO2) OVER() - MIN(NO2) OVER(), 0)) / 3 AS max_AQS
    FROM trajectories
    GROUP BY time_period, is_stop
)
SELECT time_period, is_stop, avg_AQS, min_AQS, max_AQS
FROM aqs_by_period
ORDER BY time_period, is_stop;
```

---



